{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.interpolate import interp1d"
      ],
      "metadata": {
        "id": "VK3vkSyVyIKv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9l0W45WZprs4"
      },
      "outputs": [],
      "source": [
        "# splits and restructures the timeseries dataframe into a training features array and target feature array with some lookback period and a shift step\n",
        "# can be used as input for CNN and RNN (LSTM, GRU, ...)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def lookback_arr(df: pd.DataFrame, training_feats: list, target_feats: list, lookback = 24, step = 1, n_ahead = 1):\n",
        "\n",
        "  \"\"\"\n",
        "    Creates lookback windows and corresponding target arrays from a time series DataFrame for model training.\n",
        "\n",
        "    Args:\n",
        "        df: A Pandas DataFrame with time series data.\n",
        "        training_feats: A list of column names to use as input features (including past target values).\n",
        "        target_feats: A list of column names to use as target variables for prediction.\n",
        "        lookback: The number of past time steps to include in each lookback window.\n",
        "        step: The number of time steps to move the window forward for each sample (default: 1).\n",
        "        n_ahead: The number of future time steps to predict (default: 1).\n",
        "\n",
        "    Returns:\n",
        "        A tuple of two NumPy arrays:\n",
        "            - X: A 3D array of shape (num_samples, lookback, num_features) containing the lookback windows.\n",
        "            - y: A 1D or 2D array of shape (num_samples,) or (num_samples, n_ahead) containing the target values.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  assert isinstance(df, pd.DataFrame), \"Input timeseries data must be a pandas DataFrame.\"\n",
        "  new_df = df.copy()\n",
        "\n",
        "  assert len(new_df)> lookback, \"There are fewer observations than the lookback period requires. Add more observations or reduce the lookback period.\"\n",
        "\n",
        "  for name in training_feats:\n",
        "    assert name in new_df.columns, f\"{name} training column is not present in the timeseries dataframe\"\n",
        "\n",
        "  for target in target_feats:\n",
        "    assert target in new_df.columns, f\"{target} target column is not present in the timeseries dataframe\"\n",
        "    assert target in training_feats, f\"{target} target column not in training column list. Required for lookback window. Past target values will be used for training to predict future target values\"\n",
        "\n",
        "  X, y = [], []\n",
        "\n",
        "  lb = lookback\n",
        "\n",
        "  all_training_values = new_df[training_feats].values #includes target values from the past\n",
        "  all_target_values = new_df[target_feats].values # one-step ahead target values\n",
        "\n",
        "  while lb + n_ahead< len(new_df):\n",
        "      sliced_training_df = all_training_values[:lb, :] #determines the lookback length of the timeseries observation window\n",
        "      sliced_target_df = all_target_values[lb:lb + n_ahead,:] #n_ahead determines the number of perdiods ahead you want to predict\n",
        "\n",
        "      X.append(sliced_training_df)\n",
        "      y.append(sliced_target_df)\n",
        "\n",
        "      lb+=step\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  if y.shape[1]==1: #only one target feature--> reduce from 2-d to 1-d\n",
        "    y = y.reshape(-1)\n",
        "\n",
        "  return X.astype(np.float32), y.astype(np.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# interpolates missing values in a timeseries dataframe using polynomial interpolation\n",
        "# ONLY FOR NUMERICAL DATA (IGNORES CATEGORICALS)\n",
        "\n",
        "def poly_interpolate(df, order, time_col_name, freq):\n",
        "\n",
        "  \"\"\"\n",
        "    Performs polynomial interpolation on a time series DataFrame, handling missing timestamps.\n",
        "\n",
        "    This function first fills in any missing timestamps in the specified time column using\n",
        "    forward-filling and the given frequency. Then, it performs polynomial interpolation\n",
        "    on all numerical columns to fill in missing values within the existing time range.\n",
        "\n",
        "    Args:\n",
        "        df: A Pandas DataFrame with a time column and numerical columns to interpolate.\n",
        "        order: The order of the polynomial used for interpolation (default: 2, quadratic). Must be a positive integer.\n",
        "        time_col_name: The name of the column containing datetime values (default: \"Date\").\n",
        "        freq: The frequency of the time series for filling missing timestamps (e.g., 'H' for hourly, 'D' for daily). Defaults to \"D\" (daily).\n",
        "\n",
        "    Returns:\n",
        "        A new DataFrame with interpolated values for the numerical columns and a complete DatetimeIndex.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'df' is not a DataFrame, 'order' is not a positive integer,\n",
        "                    or the specified time column is not found.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  assert isinstance(df, pd.DataFrame), \"Input must be a Pandas DataFrame\"\n",
        "  assert isinstance(order, int) and order >= 1, \"Order must be a positive integer\"\n",
        "\n",
        "  new_df = fill_missing_timestamps(df, time_col_name, freq)\n",
        "\n",
        "  df_interpolated = new_df.interpolate(method='polynomial', order = order) # order specifies the order of the polynomial (linear (1), quadratic (2), cubic (3))\n",
        "\n",
        "  return df_interpolated\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IU0XnCIEwles"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interpolates time\n",
        "#make sure time sure time is column not an index during input\n",
        "\n",
        "def fill_missing_timestamps(df: pd.DataFrame, date_column_name: str, freq: str) -> pd.DataFrame:\n",
        "    \"\"\"Fills missing timestamps in a DataFrame's datetime column by incrementing the previous valid timestamp.\n",
        "\n",
        "       Starts of with an incomplete time column and ouputs a new dataframe with an imputed DateTime index based on the given frequency.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the datetime column.\n",
        "        date_column_name (str): The name of the column containing datetime values.\n",
        "        freq (str): The frequency of the time series (e.g., 'H' for hourly, 'T' for minute, 'D' for daily).\n",
        "\n",
        "    Inputs: pd.DataFrame: A DataFrame with an incomplete time column (has NANs or missing values).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with filled timestamps as index.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input validation\n",
        "    assert isinstance(df, pd.DataFrame), \"Input must be a Pandas DataFrame.\"\n",
        "    assert date_column_name in df.columns, f\"Column '{date_column_name}' not found.\"\n",
        "\n",
        "    # Copy DataFrame to avoid modifying the original\n",
        "    df_filled = df.copy()\n",
        "\n",
        "    # Convert to datetime before filling\n",
        "    df_filled[date_column_name] = pd.to_datetime(df_filled[date_column_name])\n",
        "\n",
        "    # Create a series with a complete datetime index\n",
        "    complete_dates = pd.date_range(start=df_filled[date_column_name].min(),\n",
        "                                  end=df_filled[date_column_name].max(),\n",
        "                                  freq=freq)\n",
        "\n",
        "    # Identify missing timestamps\n",
        "    missing_dates = complete_dates.difference(df_filled[date_column_name])\n",
        "\n",
        "    # Create a new DataFrame with the missing dates and NaN values for other columns\n",
        "    df_missing = pd.DataFrame(index=missing_dates, columns=df_filled.columns)\n",
        "    df_missing[date_column_name] = missing_dates  # Fill the date column\n",
        "\n",
        "    # Concatenate and sort\n",
        "    df_filled = pd.concat([df_filled, df_missing]).sort_index()\n",
        "\n",
        "    # Fill missing values in the date column by incrementing\n",
        "    df_filled[date_column_name] = df_filled[date_column_name].fillna(method='ffill') + pd.to_timedelta('1' + freq)\n",
        "\n",
        "    # put the imputed time column as index and remove its column equivalent\n",
        "    df_filled.set_index(date_column_name, inplace=True)\n",
        "    df_filled.drop(columns=[date_column_name], inplace=True)\n",
        "\n",
        "\n",
        "    return df_filled\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UKXmfpSdzjAU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Z-score normalization of timeseries data\n",
        "\n",
        "# to prevent data leakage the values will only be normalized based on past values, determined by some lookback period\n",
        "\n",
        "# best use is for price and volume data, not necessarily for indicators like (RSI, MACD, ...)\n",
        "\n",
        "# ideally the lookback should be the same as the lookback period of the training array used to train the LSTM (RNN) or CNN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def normalize_rolling_mean(df: pd.DataFrame, columns_to_normalize: list, lookback: int, date_column_name:str, freq:str)->pd.DataFrame:\n",
        "\n",
        "  \"\"\"\n",
        "    Normalizes specified columns in a time series DataFrame using a rolling window of means (useful for price and volume data).\n",
        "\n",
        "    Args:\n",
        "        df: The DataFrame to normalize. Must have a datetime index or a datetime column specified by 'date_column_name'.\n",
        "        columns_to_normalize: List of column names to normalize.\n",
        "        lookback: The number of past periods to use for calculating rolling means.\n",
        "        date_column_name: The name of the datetime column (default is 'Date'). Used if the DataFrame does not have a datetime index.\n",
        "        freq: The frequency of the time series (e.g., 'H' for hourly, 'D' for daily) if missing timestamps need to be filled. Defaults to \"D\" (daily).\n",
        "\n",
        "    Returns:\n",
        "        A new DataFrame with the specified columns normalized using rolling means.\n",
        "    \"\"\"\n",
        "\n",
        "  # Ensure datetime index if not already set; if so impute and set it as index, as well remove the old time column\n",
        "  if not isinstance(df.index, pd.DatetimeIndex):\n",
        "    df = fill_missing_timestamps(df, date_column_name, freq)\n",
        "\n",
        "    # Initialize empty dataframe to store normalized data\n",
        "  df_normalized = pd.DataFrame(index=df.index, columns=df.columns)\n",
        "\n",
        "  for col in columns_to_normalize:\n",
        "    scaler = StandardScaler()\n",
        "    # Initialize with lookback NaNs to avoid leakage\n",
        "    df_normalized[col] = [np.nan] * lookback\n",
        "    # Calculate rolling means, ignoring initial NaNs\n",
        "    rolling_means = df[col].rolling(window=lookback).mean()[lookback:].values.reshape(-1, 1)\n",
        "    # Fit scaler to rolling means and transform the rest of the data\n",
        "    df_normalized[col][lookback:] = scaler.fit_transform(rolling_means)\n",
        "\n",
        "  # Fill the other columns with their original values\n",
        "  for col in df.columns:\n",
        "    if col not in columns_to_normalize:\n",
        "      df_normalized[col] = df[col]\n",
        "\n",
        "  return df_normalized  # Return the normalized DataFrame\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0lx8gUc8K4pD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_indicators(df:pd.DataFrame, columns_to_normalize: list)->pd.DataFrame:\n",
        "\n",
        "  \"\"\"\n",
        "    Z-score normalizes specified columns in a DataFrame (good for indicator normalization).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the indicators.\n",
        "        columns_to_normalize (list): A list of column names to normalize.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with the normalized columns.\n",
        "    \"\"\"\n",
        "\n",
        "  # make a copy\n",
        "  df_normalized = df.copy()\n",
        "\n",
        "  # normalize the specified columns\n",
        "  scaler = StandardScaler()\n",
        "  df_normalized[columns_to_normalize] = scaler.fit_transform(df_normalized[columns_to_normalize].values.reshape(-1,1))\n",
        "\n",
        "  # return the normalized column\n",
        "  return df_normalized\n"
      ],
      "metadata": {
        "id": "DtF4pA0_8s3E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mostly for price and volume data\n",
        "\n",
        "def log_returns(df:pd.DataFrame, column_names: list)->pd.DataFrame:\n",
        "\n",
        "  \"\"\"\n",
        "    Calculates log returns for specified columns in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df: The DataFrame containing the columns to calculate log returns for.\n",
        "        column_names: A list of column names to calculate log returns for.\n",
        "\n",
        "    Returns:\n",
        "        A new DataFrame with the log returns columns added.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If any specified column is not found in the DataFrame or contains missing values.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  for column in column_names:\n",
        "    assert column in df.columns, f\"{column} column not found in provided DataFrame\"\n",
        "    assert not df[column].isna().any(), f\"{column} column has missing values (NAN)\"\n",
        "\n",
        "    # convert to float64 if not already float\n",
        "    if df[column].dtype != np.float64:\n",
        "      df[column] = df[column].astype(np.float64)\n",
        "\n",
        "    df[f'log_ret_{column}'] = np.log(df[column]/df[column].shift(1)).fillna(0)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "mJxPu6ioGPOv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perc_change(df:pd.DataFrame, column_names: list, inplace: bool=False)-> pd.DataFrame:\n",
        "\n",
        "  \"\"\"\n",
        "  Calculates the percentage change for specified columns in a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df: The DataFrame containing the columns.\n",
        "        column_names: A list of column names to calculate percentage changes for.\n",
        "        inplace: If True, modifies the original DataFrame. If False (default), returns a new DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        If inplace is True, returns None (original DataFrame is modified).\n",
        "        If inplace is False, returns a new DataFrame with the calculated percentage change columns.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If a specified column is not found or contains missing values.\n",
        "        ZeroDivisionError: If a column contains zero values.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  for column in column_names:\n",
        "\n",
        "    if column not in df.columns:\n",
        "      raise ValueError(f'Column {column} not found in DataFrame')\n",
        "    if df[column].isna().any():\n",
        "      raise ValueError(f\"Column {column} has missing values (NaN)\")\n",
        "    if (df[column]==0).any():\n",
        "      raise ZeroDivisionError(f\"Column {column} contains zero values. Division by zero is not possible.\")\n",
        "\n",
        "    # convert to float64 if not already float\n",
        "    if df[column].dtype != np.float64:\n",
        "      df[column] = df[column].astype(np.float64)\n",
        "\n",
        "    #calculate the percent change (keeping it in decimal form)\n",
        "    df[f'perc_change_{column}'] = (df[column]-df[column].shift(1))/df[column].shift(1).fillna(1)\n",
        "\n",
        "  return None if inplace else df"
      ],
      "metadata": {
        "id": "3itDclolabM7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def spline_interpolate_features(df: pd.DataFrame, training_features: list, date_column_name: str, freq: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Imputes missing values in specified training features of a time series DataFrame using cubic spline interpolation.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame with potential missing values.\n",
        "        training_features (list): A list of column names representing the features to interpolate.\n",
        "        date_column_name (str, optional): The name of the datetime column (default: \"Date\").\n",
        "        freq (str, optional): The frequency of the time series for filling missing timestamps (default: \"D\").\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with imputed values in the specified training features.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If 'df' is not a DataFrame, the datetime column is not found,\n",
        "                    or any specified training feature is not found in the DataFrame.\n",
        "        TypeError: If the datetime column is not in datetime format.\n",
        "        Exception: If there are not enough non-NaN values for spline interpolation in a feature.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input Validation:\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "        raise ValueError(\"Input must be a Pandas DataFrame.\")\n",
        "    if date_column_name not in df.columns:\n",
        "        raise ValueError(f\"Column '{date_column_name}' not found in DataFrame.\")\n",
        "\n",
        "    for feature in training_features:\n",
        "        if feature not in df.columns:\n",
        "            raise ValueError(f\"Training feature '{feature}' not found in DataFrame.\")\n",
        "\n",
        "    # Create a complete and filled datetime index\n",
        "    df_filled = fill_missing_timestamps(df, date_column_name, freq)\n",
        "\n",
        "    # Convert the DatetimeIndex to numeric for interp1d\n",
        "    x = df_filled.index.astype(np.int64) / 10 ** 9\n",
        "\n",
        "    # Interpolate only the specified training features\n",
        "    for col in training_features:\n",
        "        y = df_filled[col].dropna().values\n",
        "        if len(y) > 3:\n",
        "            f = interp1d(x[df_filled[col].notnull()], y, kind='cubic')\n",
        "            df_filled[col] = f(x)\n",
        "        else:\n",
        "            raise Exception(f\"Not enough non-NaN values in column '{col}' for spline interpolation.\")\n",
        "\n",
        "    return df_filled  # Return the DataFrame with imputed training features\n"
      ],
      "metadata": {
        "id": "AbQj6Ti2aiv2"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}